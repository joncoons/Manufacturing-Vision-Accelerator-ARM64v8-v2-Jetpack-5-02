# FROM nvcr.io/nvidia/l4t-ml:r35.1.0-py3
# FROM nvcr.io/nvidia/l4t-cuda:11.4.14-runtime

# FROM nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.13-py3
FROM nvcr.io/nvidia/l4t-tensorrt:r8.4.1-runtime

WORKDIR /app

RUN apt update && apt install -y --no-install-recommends \
    wget \
    # per Nvidia: https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#:~:text=The%20NVIDIA%C2%AE%20CUDA%C2%AE%20Deep%20Neural%20Network,the%20NVIDIA%20Deep%20Learning%20%20SDK.&text=The%20NVIDIA%C2%AE%20CUDA%C2%AE%20Deep,Deep%20Learning%20%20SDK.&text=CUDA%C2%AE%20Deep%20Neural%20Network,the%20NVIDIA%20Deep%20Learning
    zlib1g && \
    rm -rf /var/lib/apt/lists/*

# https://repo.download.nvidia.com/jetson/
# RUN wget https://repo.download.nvidia.com/jetson/common/pool/main/c/cudnn/libcudnn8_8.2.1.32-1+cuda10.2_arm64.deb && dpkg -i libcudnn8_8.2.1.32-1+cuda10.2_arm64.deb \
#     && rm libcudnn8_8.2.1.32-1+cuda10.2_arm64.deb

COPY qemu-aarch64-static /usr/bin/qemu-aarch64-static
RUN cd /usr/bin && chmod a+rwx qemu-aarch64-static
ARG DEBIAN_FRONTEND=noninteractive
ARG INSTALL_FOLDER=cv2_files
ENV runtime=nvidia
ENV CUDA_HOME=/usr/local/cuda-11.4:$CUDA_HOME
ENV CUDA_PATH=/usr/local/cuda:$CUDA_PATH
ENV CUDNN_HOME=/usr/lib/aarch64-linux-gnu:$CUDNN_HOME

COPY requirements.txt ./

# Create folder structure and set permissions
# When combined with deployment manifest, an edge_assets directory will be created on the host device
RUN mkdir /model_volume && chmod -R 777 /model_volume
RUN mkdir /images_volume && chmod -R 777 /images_volume
RUN mkdir /image_sink_volume && chmod -R 777 /image_sink_volume
RUN mkdir /config && chmod -R 777 /config

RUN apt update && apt install -y --no-install-recommends \
    ca-certificates \
    libprotobuf-dev \
    protobuf-compiler \
    libgfortran4 \
    libopenblas-base \
    libopenmpi-dev \
    libomp-dev \
    build-essential \
    # software-properties-common \
    libopenblas-dev \
    python3-pip \
    python3-dev \
    cmake \
    # libgstreamer1.0-dev \
    # libgstreamer-plugins-base1.0-dev \
    # libtbb2 \
    # libtbb-dev \
    # libjpeg-dev \
    # libpng-dev \
    # libtiff-dev \
    # libdc1394-22-dev \
    # libwebp-dev \
    # libv4l-dev \
    # v4l-utils \
    # libavcodec-dev \
    # qv4l2 \
    ffmpeg \
    libsm6 \
    libxext6 \
    libgeos-dev &&\
    python3 -m pip install --upgrade pip wheel setuptools requests && \
    python3 -m pip install -r requirementts.txt && \
    wget https://nvidia.box.com/shared/static/v59xkrnvederwewo2f1jtv6yurl92xso.whl -O onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl && \
    python3 -m pip install onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl && \
    rm -rf onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl && \
    apt remove --purge -y wget cmake build-essential python3-pip && \
    apt autoremove --purge &&\ 
    apt clean

# RUN apt update && apt install -y --no-install-recommends \
#     libavcodec-dev && \
#     rm -rf /var/lib/apt/lists/* && \
#     apt autoremove --purge &&\ 
#     apt clean

# RUN python3 -m pip install --upgrade pip wheel setuptools requests
# RUN python3 -m pip install protobuf

# ENV CUDA_HOME=/usr/local/cuda-11.4:$CUDA_HOME
# ENV CUDA_PATH=/usr/local/cuda:$CUDA_PATH
# ENV CUDNN_HOME=/usr/lib/aarch64-linux-gnu:$CUDNN_HOME

#  https://elinux.org/Jetson_Zoo
# RUN wget https://nvidia.box.com/shared/static/v59xkrnvederwewo2f1jtv6yurl92xso.whl -O onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl
# RUN python3 -m pip install onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl
# RUN rm -rf onnxruntime_gpu-1.12.1-cp38-cp38-linux_aarch64.whl


#  https://elinux.org/Jetson_Zoo
# RUN wget https://developer.download.nvidia.com/compute/redist/jp/v50/pytorch/torch-1.12.0a0+2c916ef.nv22.3-cp38-cp38-linux_aarch64.whl 
# RUN python3 -m pip install torch-1.12.0a0+2c916ef.nv22.3-cp38-cp38-linux_aarch64.whl
# RUN rm -rf torch-1.12.0a0+2c916ef.nv22.3-cp38-cp38-linux_aarch64.whl

# https://download.pytorch.org/whl/torchvision/
# RUN wget https://download.pytorch.org/whl/torchvision-0.13.1-cp38-cp38-manylinux2014_aarch64.whl
# RUN python3 -m pip install torchvision-0.13.1-cp38-cp38-manylinux2014_aarch64.whl
# RUN rm -rf torchvision-0.13.1-cp38-cp38-manylinux2014_aarch64.whl

# Comment out if not using Allied Vision camera
COPY VimbaSDK/Vimba_v5.1_ARM64.tgz /opt
RUN cd /opt && tar -zxvf Vimba_v5.1_ARM64.tgz && rm -rf *.tgz
RUN cd /opt/Vimba_5_1/VimbaGigETL && ./Install.sh
ENV GENICAM_GENTL64_PATH="/opt/Vimba_5_1/VimbaGigETL/CTI/arm_64bit"
RUN echo "$GENICAM_GENTL64_PATH"
RUN cd /opt/Vimba_5_1/Tools/Viewer/Bin/arm_64bit && chmod +x libVimbaC.so && chown root:root libVimbaC.so 
RUN cp /opt/Vimba_5_1/Tools/Viewer/Bin/arm_64bit/libVimbaC.so /usr/lib/aarch64-linux-gnu

# RUN apt update && apt install -y --no-install-recommends \
#     ffmpeg \
#     libsm6 \
#     libxext6 && \
#     rm -rf /var/lib/apt/lists/* && \
#     apt autoremove --purge &&\ 
#     apt clean

# WORKDIR /app

COPY /app/ .

ENV OPENBLAS_CORETYPE=ARMV8:$OPENBLAS_CORETYPE
ENV LD_LIBRARY_PATH=/usr/lib/aarch64-linux-gnu:$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=/usr/local/lib/python3.8/dist-packages/opencv_contrib_python_headless.libs:$LD_LIBRARY_PATH
ENV PATH=/usr/local/cuda-11.4/bin:$PATH
ENV PATH=/usr/lib/aarch64-linux-gnu:$PATH
ENV PYTHONPATH=$PYTHONPATH:/app/inference
ENV LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1:$LD_PRELOAD
ENV LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libcudnn.so.8:$LD_PRELOAD

RUN ldconfig

CMD [ "python3", "-u", "./main.py" ]